# RepE Scenario Probe Training Configuration
# Uses DeceptionQAnew dataset (200 spy/resistance scenarios with lie/truth instructions)

model_name_or_path: "gemma_2_9b_instruct"  # Can be changed to a finetuned checkpoint

# Probe configurations
probes:
  logistic_repe_scenarios:
    type: "logistic"
    learning_rate: 4e-5
    batch_size: 8  # Smaller batch size due to smaller dataset
    num_epochs: 3  # More epochs since dataset is smaller
    target_layers: [12]
    pooling_type: "mean"
    max_samples: null  # Use all available training data (~160 examples)
    max_test_samples: null  # Use all test data (~40 examples)

training_datasets:
  train:
    positive: ["repe_scenario_deceptive_train"]  # Scenarios with lie instructions
    negative: ["repe_scenario_honest_train"]     # Scenarios with truth instructions

test_datasets:
  test:
    positive: ["repe_scenario_deceptive_test"]   # Held-out lie scenarios
    negative: ["repe_scenario_honest_test"]      # Held-out truth scenarios

# Note: This dataset is much smaller (200 total examples) 
# so results may be less stable than the honesty dataset

wandb_project: "probe-training-repe"
wandb_entity: null
wandb_name: "repe_scenario_probe"
wandb_tags: ["repe", "scenarios", "deception", "spy"]