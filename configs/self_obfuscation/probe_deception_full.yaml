model_name_or_path: "gemma_2_9b_instruct"

# Probe configurations
probes:
  logistic_baseline:
    type: "logistic"
    learning_rate: 1e-3
    batch_size: 16
    num_epochs: 1
    target_layers: [12]
    pooling_type: "mean"

training_datasets:
  train:
    positive: ["dolus_deceptive_train"]
    negative: ["dolus_benign_train"]

test_datasets:
  test:
    positive: ["dolus_deceptive_test"]
    negative: ["dolus_benign_test"]

wandb_project: "probe-training"
wandb_entity: 4002tsa
wandb_name: null
wandb_tags: []
